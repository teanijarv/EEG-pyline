{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes in Resting-State EEG Aperiodic 1/f Activity, Theta Oscillations, and Episodic Memory Performance in Healthy Adolescents and Older Adults\n",
    "\n",
    "Authors: Anijärv, T.E., Campbell, A.J., Hermens, D.F., Lagopoulos, J. & Andrews, S.C.\n",
    "\n",
    "Code created by Toomas Erik Anijärv in 08.02.2023\n",
    "\n",
    "This notebook is a representation of EEG processing done for the publication with pre-processing shown with one participant, spectral analysis with two participants and final results (data visualisation) with the full dataset.\n",
    "\n",
    "You are free to use this or any other code from this repository for your own projects and publications. Citation or reference to the repository is not required, but would be much appreciated (see more on README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne, os, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections  import PathCollection\n",
    "from matplotlib.lines  import Line2D\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "from fooof import FOOOF\n",
    "from fooof.plts.spectra import plot_spectrum, plot_spectrum_shading\n",
    "from fooof.plts.aperiodic import plot_aperiodic_params, plot_aperiodic_fits\n",
    "from fooof.plts.periodic import plot_peak_params\n",
    "from statannotations.Annotator import Annotator\n",
    "import HLR\n",
    "\n",
    "# Set the current working directory to be the project main folder\n",
    "os.chdir('/Users/tanijarv/Documents/GitHub/EEG-pyline')\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "import basic.arrange_data as arrange\n",
    "import signal_processing.pre_process as pre_process\n",
    "import signal_processing.spectral_analysis as spectr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locating the EEG files in folders** by define the experiment sub-folder (`exp_folder`), folder with raw EEG files (`raw_folder`), folder for exporting clean EEG files (`clean_folder`), and folder for exporting the results (`results_folder`).\n",
    "\n",
    "During pre-processing, all the raw EEG files are cleaned from the `raw_folder/exp_folder` and later saved to `clean_folder/exp_folder`. For analysis, the same clean files are read in and worked on until the results are exported to `results_folder/exp_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE ###\n",
    "raw_folder = 'Data/Raw/'\n",
    "clean_folder = 'Data/Clean/'\n",
    "\n",
    "exp_folder = 'LABS/Eyes Closed/T6'\n",
    "exp_condition = 'EC_T6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing** within this study includes initially reading the raw EEG files from `raw_folder/exp_folder`, setting montage (`biosemi32`), re-referencing the signals to `mastoid`, cropping the EEG signal to include only the `resting` part.\n",
    "\n",
    "Furthermore, `0.5-30 Hz FIR filter` is designed (`zero-phase, Hamming window, order 6578`) and EOG channels are used to remove EOG-related noise with `signal-space projections (SSP)` as method.\n",
    "\n",
    "Finally, artefacts are rejected with Autoreject package by removing epochs which exceed the global thereshold voltage level (`global AR`) and rest of the artefactual epochs are either removed or interpreted with `local AR`.\n",
    "\n",
    "The clean EEG signals are exported to `clean_folder/exp_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE ###\n",
    "montage = 'biosemi32'\n",
    "eog_channels = ['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8'] # EOG channels + mastoids\n",
    "stimulus_channel = 'Status'\n",
    "reference = 'average' # average as reference\n",
    "epochs_duration = 5\n",
    "filter_design = dict(l_freq=0.5,h_freq=30,filter_length='auto',method='fir',\n",
    "                     l_trans_bandwidth='auto',h_trans_bandwidth='auto',\n",
    "                     phase='zero',fir_window='hamming',fir_design='firwin')\n",
    "\n",
    "# Set the directory in progress and find all BDF (raw EEG) files in there\n",
    "dir_inprogress = os.path.join(raw_folder,exp_folder)\n",
    "export_dir = os.path.join(clean_folder,exp_folder)\n",
    "file_dirs, subject_names = arrange.read_files(dir_inprogress,'.bdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_dirs)):\n",
    "    # Read in the raw EEG data\n",
    "    raw = mne.io.read_raw_bdf(file_dirs[i], infer_types=True, eog=eog_channels,\n",
    "                              stim_channel=stimulus_channel)\n",
    "\n",
    "    # Set the right montage (Biosemi32) and set reference as average across all channels\n",
    "    raw = raw.set_montage(mne.channels.make_standard_montage(montage)).load_data()\\\n",
    "             .set_eeg_reference(ref_channels=reference, verbose=True)\n",
    "\n",
    "    # Find event markers for the start and end of resting state recordings\n",
    "    events = mne.find_events(raw, stim_channel=stimulus_channel, consecutive=False, output='offset')\n",
    "    tminmax = [events[0][0]/raw.info['sfreq'], events[-1][0]/raw.info['sfreq']]\n",
    "\n",
    "    # Use the markers to crop to EEG signal to leave only the actual resting state\n",
    "    cropped_raw = raw.crop(tmin=tminmax[0], tmax=tminmax[1])\n",
    "    cropped_raw = cropped_raw.drop_channels(stimulus_channel)\n",
    "    print(('Event markers are following:\\n{}\\nStarting point: {} s\\nEnding point: {} s\\n'\n",
    "           'Total duration: {} s').format(events, tminmax[0], tminmax[1], tminmax[1]-tminmax[0]))\n",
    "    \n",
    "    # Filter the signal with bandpass filter and remove EOG artefacts with SSP\n",
    "    filt = pre_process.filter_raw_data(cropped_raw, filter_design, line_remove=None,\n",
    "                                       eog_channels=eog_channels, plot_filt=False, savefig=False)\n",
    "\n",
    "    # Divide the filtered signal to epochs and run Autoreject artefact rejection on the epochs\n",
    "    %matplotlib inline\n",
    "    epochs = pre_process.artefact_rejection(filt,subject_names[i],epo_duration=epochs_duration)\n",
    "\n",
    "    # (Optional) for displaying interactive EEG plots to visually inspect the signal quality\n",
    "    #%matplotlib qt\n",
    "    #epochs.plot(n_channels=32,n_epochs=1)\n",
    "\n",
    "    # Try to create a directory and save the EEG file to that directory\n",
    "    try:\n",
    "        os.makedirs(export_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    try:\n",
    "        mne.Epochs.save(epochs,fname='{}/{}_clean-epo.fif'.format(export_dir,subject_names[i]),\n",
    "                                                                  overwrite=True)\n",
    "    except FileExistsError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECTRAL ANALYSIS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locating the EEG files in folders** by defining the experiment sub-folders (`exp_folder`), folder with clean EEG files (`clean_folder`), and folder for exporting the results (`results_folder`).\n",
    "\n",
    "During spectral analysis, all the clean EEG files are analysed and exported to `results_folder/exp_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE ###\n",
    "clean_folder = 'Data/Clean/'\n",
    "spectra_folder = 'Data/Spectra/'\n",
    "results_folder = 'Results/'\n",
    "\n",
    "exp_folder = ['LABS-LEISURE/Eyes Closed/LEISURE', 'LABS-LEISURE/Eyes Closed/LABS']\n",
    "exp_condition = ['LEISURE', 'LABS']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectral analysis** within this study includes estimating `Welch's power spectrum density (PSD)` for all the participants at five brain regions (i.e., `frontal`, `parietal`, `left-temporal`, `right-temporal` and `occipital`). The PSDs are fitted with `specparam` (`FOOOF`) model to estimate aperiodic 1/f-like component in the spectra which can be described with parameters `exponent` and `offset`. After that, the spectrum is flattened by substracting aperiodic component from the spectrum and within the given alpha band (`7-14 Hz`), a maximum power value, i.e. peak, is detected and its amplitude (i.e. `alpha power width`) and frequency (i.e. `alpha center frequency`) are exported. Finally, `absolute alpha band power` is calculated from the flattened spectrum by averaging PSD estimate within the center frequency and its bandwidth of 6 Hz (e.g., CF=10.4Hz -> alpha band=7.4-13.4Hz) and `relative alpha band power` is calculated by dividing the absolute band power by the broadband power (i.e., average PSD across all spectrum).\n",
    "\n",
    "Welch's PSD is calculated for `1-30 Hz` frequency range using `2.5-second Hamming window (50% overlap)` and 39 times the window (97.5 seconds) zero-padding (for more interpolated frequency points when finding center frequency of the alpha peak).\n",
    "\n",
    "The FOOOF (specparam) algorithm (version 1.0.0) was used to parameterize neural power spectra. Settings for the algorithm were set as: `peak width limits : 1-12 Hz`; `max number of peaks : infinite`; `minimum peak height : 0.225 uV^2`; `peak threshold : 2.0 uV^2`; and `aperiodic mode : fixed`. Power spectra were parameterized across the frequency range `1-30 Hz`. The aperiodic 1/f-like fit is described with the following function, where $S$ is aperiodic component, $b$ is `offset`, $F$ is vector of frequencies, and $e$ is `exponent`:\n",
    "\n",
    "$S=b-log(F^e)$\n",
    "\n",
    "The results are saved as Excel spreadsheets regionally to `results_folder/exp_folder/FOOOF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE ###\n",
    "bands = {'Theta' : [4, 8]}\n",
    "brain_regions = {'Frontal' : ['AF3', 'F3', 'FC1', 'AF4', 'F4', 'FC2'],\n",
    "                 'Temporal' : ['F7', 'FC5', 'T7', 'F8', 'FC6', 'T8'],\n",
    "                 'Parietal' : ['CP5', 'P3', 'P7', 'CP6', 'P4', 'P8']}\n",
    "flat_spectr_scale = 'linear'\n",
    "plot_rich = True\n",
    "savefig = True\n",
    "savespectrum = True\n",
    "psd_params = dict(method='welch', fminmax=[1, 30], window='hamming', window_duration=2.5,\n",
    "                  window_overlap=0.5, zero_padding=3)\n",
    "fooof_params = dict(peak_width_limits=[1,12], max_n_peaks=float(\"inf\"), min_peak_height=0.225,\n",
    "                    peak_threshold=2.0, aperiodic_mode='fixed')\n",
    "\n",
    "spectrum_name = psd_params['method']+'_'+str(psd_params['fminmax'][0])+'-'+str(psd_params['fminmax'][1])+'Hz_WIN='+str(\n",
    "                psd_params['window_duration'])+'s_'+psd_params['window']+'_OL='+str(psd_params['window_overlap']*\n",
    "                100)+'%_ZP='+str(psd_params['zero_padding']*psd_params['window_duration'])+'s'\n",
    "\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through both experiment folders\n",
    "for exp in range(len(exp_folder)):\n",
    "    # Set the directory in progress and find all FIF (clean EEG) files in there\n",
    "    dir_inprogress = os.path.join(clean_folder, exp_folder[exp])\n",
    "    file_dirs, subject_names = arrange.read_files(dir_inprogress, '_clean-epo.fif')\n",
    "    arrange.create_results_folders(exp_folder=exp_folder[exp], results_folder=results_folder, fooof=True)\n",
    "\n",
    "    if savespectrum == True:\n",
    "        try:\n",
    "            os.makedirs(os.path.join('{}/{}/{}'.format(spectra_folder, exp_folder[exp], spectrum_name)))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        try:\n",
    "            os.makedirs(os.path.join('{}/{}/{}'.format(results_folder, exp_folder[exp], spectrum_name)))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "    for i in range(len(file_dirs)):\n",
    "        # Read in the clean EEG data\n",
    "        epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress, subject_names[i]),\n",
    "                                                                    verbose=False)\n",
    "        \n",
    "        # Calculate Welch's power spectrum density\n",
    "        [psds,freqs] = spectr.calculate_psd(epochs, subject_names[i], method=psd_params['method'],\n",
    "                                            fminmax=psd_params['fminmax'], window=psd_params['window'],\n",
    "                                            window_duration=psd_params['window_duration'],\n",
    "                                            window_overlap=psd_params['window_overlap'],\n",
    "                                            zero_padding=psd_params['zero_padding'],\n",
    "                                            verbose=True, plot=False)\n",
    "        \n",
    "        # Average all epochs and channels together -> (freq bins,) shape\n",
    "        if i == 0:\n",
    "            psds_allch = np.zeros(shape=(len(file_dirs), len(freqs)))\n",
    "        psds_allch[i] = psds.mean(axis=(0, 1))\n",
    "\n",
    "        # Average all epochs together for each channel and also for each region\n",
    "        psds = psds.mean(axis=(0))\n",
    "        df_psds_ch = arrange.array_to_df(subject_names[i], epochs, psds).\\\n",
    "                             reset_index().drop(columns='Subject')\n",
    "        df_psds_regions = arrange.df_channels_to_regions(df_psds_ch, brain_regions).\\\n",
    "                                  reset_index().drop(columns='Subject')\n",
    "\n",
    "        # Go through all regions of interest\n",
    "        for region in df_psds_regions.columns:\n",
    "            if i == 0:\n",
    "                globals()[\"df_fooof_\"+region] = pd.DataFrame(index=subject_names)\n",
    "                globals()[\"df_powerspectra_\"+region] = pd.DataFrame(columns=freqs, index=subject_names)\n",
    "                globals()[\"df_flatpowerspectra_\"+region] = pd.DataFrame(columns=freqs, index=subject_names)\n",
    "\n",
    "            psds_temp = df_psds_regions[region].to_numpy()\n",
    "\n",
    "            # Fit the spectrum with FOOOF (specparam)\n",
    "            fm = FOOOF(**fooof_params, verbose=True)\n",
    "            fm.fit(freqs, psds_temp, psd_params['fminmax'])\n",
    "                \n",
    "            # Log-linear conversion based on the chosen amplitude scale\n",
    "            if flat_spectr_scale == 'linear':\n",
    "                flatten_spectrum = 10 ** fm._spectrum_flat\n",
    "                flat_spectr_ylabel = 'Power (µV\\u00b2/Hz)'\n",
    "            elif flat_spectr_scale == 'log':\n",
    "                flatten_spectrum = fm._spectrum_flat\n",
    "                flat_spectr_ylabel = 'Log-normalised power (log\\u2081\\u2080[uV\\u00b2/Hz])'\n",
    "\n",
    "            # Find individual alpha band parameters\n",
    "            abs_bp, rel_bp = spectr.find_bp(flatten_spectrum, freqs, bands['Theta'])\n",
    "\n",
    "            # Set plot styles\n",
    "            data_kwargs = {'color' : 'black', 'linewidth' : 1.4, 'label' : 'Original'}\n",
    "            model_kwargs = {'color' : 'red', 'linewidth' : 1.4, 'alpha' : 0.75, 'label' : 'Full model'}\n",
    "            aperiodic_kwargs = {'color' : 'blue', 'linewidth' : 1.4, 'alpha' : 0.75,\n",
    "                                'linestyle' : 'dashed', 'label' : 'Aperiodic model'}\n",
    "            flat_kwargs = {'color' : 'black', 'linewidth' : 1.4}\n",
    "            hvline_kwargs = {'color' : 'blue', 'linewidth' : 1.0, 'linestyle' : 'dashed', 'alpha' : 0.75}\n",
    "\n",
    "            # Plot power spectrum model + aperiodic fit\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), dpi=100)\n",
    "            plot_spectrum(fm.freqs, fm.power_spectrum,\n",
    "                        ax=axs[0], plot_style=None, **data_kwargs)\n",
    "            plot_spectrum(fm.freqs, fm.fooofed_spectrum_,\n",
    "                        ax=axs[0], plot_style=None, **model_kwargs)\n",
    "            plot_spectrum(fm.freqs, fm._ap_fit,\n",
    "                        ax=axs[0], plot_style=None, **aperiodic_kwargs)\n",
    "            axs[0].set_xlim(psd_params['fminmax'])\n",
    "            axs[0].grid(linewidth=0.2)\n",
    "            axs[0].set_xlabel('Frequency (Hz)')\n",
    "            #axs[0].set_ylabel('Log-normalised power (log\\u2081\\u2080[uV\\u00b2/Hz])')\n",
    "            axs[0].set_ylabel('Log-normalised power (log$_{10}$[µV\\u00b2/Hz])')\n",
    "            axs[0].set_title('Spectrum model fit')\n",
    "            axs[0].legend()\n",
    "            \n",
    "            # Flattened spectrum plot (i.e., minus aperiodic fit)\n",
    "            plot_spectrum_shading(fm.freqs, flatten_spectrum,\n",
    "                        ax=axs[1], shades=bands['Theta'], shade_colors='green',\n",
    "                        plot_style=None, **flat_kwargs)\n",
    "            #axs[1].vlines(bands['Theta'], ymin=axs[1].get_ylim()[0], ymax=axs[1].get_ylim()[1])\n",
    "            axs[1].set_xlim(psd_params['fminmax'])\n",
    "            axs[1].grid(linewidth=0.2)\n",
    "            axs[1].set_xlabel('Frequency (Hz)')\n",
    "            axs[1].set_ylabel(flat_spectr_ylabel)\n",
    "            axs[1].set_title('Flattened spectrum')\n",
    "            #axs[1].legend()\n",
    "\n",
    "            # If true, plot all the exported variables on the plots\n",
    "            if plot_rich == True:\n",
    "                axs[0].annotate('Error: ' + str(np.round(fm.get_params('error'), 4)) +\n",
    "                            '\\nR\\u00b2: ' + str(np.round(fm.get_params('r_squared'), 4)),\n",
    "                            (0.1, 0.16), xycoords='figure fraction', color='red', fontsize=8.5)\n",
    "                axs[0].annotate('Exponent: ' + str(np.round(fm.get_params('aperiodic_params','exponent'), 4)) +\n",
    "                            '\\nOffset: ' + str(np.round(fm.get_params('aperiodic_params','offset'), 4)),\n",
    "                            (0.19, 0.16), xycoords='figure fraction', color='blue', fontsize=8.5)\n",
    "                axs[1].annotate('Absolute theta BP: '+str(np.round(abs_bp, 4))+'\\nRelative theta BP: '+str(np.round(rel_bp, 4)),\n",
    "                                (0.69, 0.16), xycoords='figure fraction', color='green', fontsize=8.5)\n",
    "            \n",
    "            plt.suptitle('{} region ({})'.format(region, subject_names[i]))\n",
    "            plt.tight_layout()\n",
    "            if savefig == True:\n",
    "                plt.savefig(fname='{}/{}/FOOOF/{}_{}_{}_fooof.png'.format(results_folder, exp_folder[exp],\n",
    "                                                                          exp_condition[exp], subject_names[i],\n",
    "                                                                          region), dpi=300)\n",
    "            plt.show()\n",
    "\n",
    "            # Add model parameters to dataframe\n",
    "            globals()[\"df_fooof_\"+region].loc[globals()[\"df_fooof_\"+region].index[i],'Exponent']\\\n",
    "                                                            = fm.get_params('aperiodic_params','exponent')\n",
    "            globals()[\"df_fooof_\"+region].loc[globals()[\"df_fooof_\"+region].index[i],'Offset']\\\n",
    "                                                            = fm.get_params('aperiodic_params','offset')\n",
    "            globals()[\"df_fooof_\"+region].loc[globals()[\"df_fooof_\"+region].index[i],'{} absolute power'.\\\n",
    "                            format(list(bands.keys())[0])] = abs_bp\n",
    "            globals()[\"df_fooof_\"+region].loc[globals()[\"df_fooof_\"+region].index[i],'{} relative power'.\\\n",
    "                            format(list(bands.keys())[0])] = rel_bp\n",
    "            globals()[\"df_fooof_\"+region].loc[globals()[\"df_fooof_\"+region].index[i],'R_2']\\\n",
    "                                                            = fm.get_params('r_squared')\n",
    "            globals()[\"df_fooof_\"+region].loc[globals()[\"df_fooof_\"+region].index[i],'Error']\\\n",
    "                                                            = fm.get_params('error')\n",
    "            \n",
    "            # Add the original and flattened power spectra to the dataframe\n",
    "            globals()[\"df_powerspectra_\"+region].loc[subject_names[i]] = fm.power_spectrum\n",
    "            globals()[\"df_flatpowerspectra_\"+region].loc[subject_names[i]] = flatten_spectrum\n",
    "\n",
    "    # Export aperiodic data for all regions\n",
    "    for region in df_psds_regions.columns:\n",
    "        globals()[\"df_fooof_\"+region].to_excel('{}/{}/FOOOF/{}_{}_fooof.xlsx'.format(results_folder,\n",
    "                                                                                    exp_folder[exp],\n",
    "                                                                                    exp_condition[exp],\n",
    "                                                                                    region))\n",
    "        display(globals()[\"df_fooof_\"+region])\n",
    "\n",
    "        if savespectrum == True:\n",
    "            globals()[\"df_powerspectra_\"+region].to_excel('{}/{}/{}/{}_powerspectra_{}.xlsx'.format(spectra_folder,\n",
    "                                                                                                    exp_folder[exp],\n",
    "                                                                                                    spectrum_name,\n",
    "                                                                                                    exp_condition[exp],\n",
    "                                                                                                    region))\n",
    "            globals()[\"df_flatpowerspectra_\"+region].to_excel('{}/{}/{}/{}_flatpowerspectra_{}.xlsx'.format(spectra_folder,\n",
    "                                                                                                            exp_folder[exp],\n",
    "                                                                                                            spectrum_name,\n",
    "                                                                                                            exp_condition[exp],\n",
    "                                                                                                            region))\n",
    "            #display(globals()[\"df_powerspectra_\"+region])\n",
    "            #display(globals()[\"df_flatpowerspectra_\"+region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTICIPANTS EXCLUSION & MASTER FILES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Participants exclusion** is done firstly by reading all the previously exported data and adding them all into single dataframe. The participants are checked for set of criteria which if they do not match, `visual inspection of the model fit and alpha peak detection` is done. The criteria are the following: $error >= 0.1$, $R^2 <= 0.9$, $alpha$ $PW <= 0$, $alpha$ $absolute$ $power <= 0$, $alpha$ $relative$ $power <= 0$. After visual inspection of these participants particularly, `participants whose model fit is bad or there is no alpha peak are removed from the dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE ###\n",
    "results_folder = 'Results/'\n",
    "savefinal_folder = 'Results/LABS-LEISURE/'\n",
    "\n",
    "exp_folder = ['LABS-LEISURE/Eyes Closed/LEISURE', 'LABS-LEISURE/Eyes Closed/LABS']\n",
    "exp_condition = ['LEISURE', 'LABS']\n",
    "\n",
    "freq_range = [1, 30]\n",
    "\n",
    "spectra_folder = 'Data/Spectra/'\n",
    "spectrum_name = 'welch_1-30Hz_WIN=2.5s_hamming_OL=50.0%_ZP=7.5s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in aperiodic spectral analysis data for all groups and regions into one dataframe\n",
    "df = pd.DataFrame()\n",
    "for exp in range(len(exp_folder)):\n",
    "    # Get Excel files location\n",
    "    dir_inprogress, filename, condition = arrange.read_excel_psd(exp_folder[exp]+'/FOOOF',\n",
    "                                                                 results_folder,\n",
    "                                                                 condition_strsplit='_fooof')\n",
    "    for i in range(len(condition)):\n",
    "        condition[i] = condition[i][0]\n",
    "\n",
    "    for reg in range(len(filename)):\n",
    "        # Read in the Excel file and set the region and group based on file name\n",
    "        df_temp = pd.read_excel('{}/{}.xlsx'.format(dir_inprogress, filename[reg]), index_col=0, engine='openpyxl')\n",
    "        df_temp['Region'] = condition[reg].split('_', 1)[1]\n",
    "        df_temp['Group'] = condition[reg].split('_', 1)[0]\n",
    "\n",
    "        # Merge the new dataframe to the master one\n",
    "        df = pd.concat([df, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all pure power spectras (original and flatten) for all groups and regions into one dataframe (for later grand average plots)\n",
    "df_psd = pd.DataFrame()\n",
    "for exp in range(len(exp_folder)):\n",
    "    # Get Excel files location\n",
    "    dir_inprogress, filename, condition = arrange.read_excel_psd(exp_folder[exp]+'/'+spectrum_name,\n",
    "                                                                 spectra_folder,\n",
    "                                                                 condition_strsplit='.')\n",
    "    for i in range(len(condition)):\n",
    "        condition[i] = condition[i][0]\n",
    "\n",
    "    for reg in range(len(filename)):\n",
    "        # Read in the Excel file and set the region and group based on file name\n",
    "        df_temp = pd.read_excel('{}/{}.xlsx'.format(dir_inprogress, filename[reg]), index_col=0, engine='openpyxl')\n",
    "        df_temp['Region'] = condition[reg].split('_', 2)[2]\n",
    "        df_temp['Type'] = condition[reg].split('_', 2)[1]\n",
    "        df_temp['Group'] = condition[reg].split('_', 2)[0]\n",
    "\n",
    "        # Merge the new dataframe to the master one\n",
    "        df_psd = pd.concat([df_psd, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display participants within the dataset who check for the set criteria\n",
    "print('\\n---\\nError >= 0.1')\n",
    "display(df[['Error', 'Region', 'Group']][df['Error']>=0.1].sort_index())\n",
    "print('\\n---\\nR^2 <= 0.6')\n",
    "display(df[['R_2', 'Region', 'Group']][df['R_2']<=0.6].sort_index())\n",
    "print('\\n---\\nExponent <= 0')\n",
    "display(df[['Exponent', 'Region', 'Group']][df['Exponent']<=0].sort_index())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed participants are following\n",
    "\n",
    "`HBA_0007_EC_T1` // bad model fit at T (exp<=0)\n",
    "\n",
    "`HBA_0009_EC_T1` // bad model fit at T (exp<=0)\n",
    "\n",
    "`HBA_0016_EC_T1` // bad model fit at F, T, P (exp<=0)\n",
    "\n",
    "`HBA_0070_EC_T1` // bad model fit at T (R2<=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants chosen visually to be removed due to either bad model fit or alpha peak detected wrongly\n",
    "bad_participants = ['HBA_0007_EC_T1', 'HBA_0009_EC_T1', 'HBA_0016_EC_T1', 'HBA_0070_EC_T1']\n",
    "\n",
    "# Remove the bad participants from the results dataframe AND PSDs dataframe\n",
    "df_wo_bads = df.drop(index=(bad_participants))\n",
    "df_psd_wo_bads = df_psd.drop(index=(bad_participants))\n",
    "\n",
    "# Export the master dataframes that do not have the \"bad\" participants\n",
    "df_wo_bads.to_excel('{}/specparam_{}.xlsx'.format(savefinal_folder, str(exp_condition)))\n",
    "df_psd_wo_bads.to_excel('{}/powerspectra_{}.xlsx'.format(savefinal_folder, str(exp_condition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_wo_bads)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA VISUALISATION & STATISTICS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data visualisation** includes plotting for each region 1) `aperiodic component of the spectra` in log-log scale and `model parameters` (i.e. exponent and offset); 2) `alpha absolute power`, `alpha relative power` and `alpha peak parameters` (i.e. center frequency and peak power)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {'Theta' : [4, 8]}\n",
    "brain_regions = {'Frontal' : ['AF3', 'F3', 'FC1', 'AF4', 'F4', 'FC2'],\n",
    "                 'Temporal' : ['F7', 'FC5', 'T7', 'F8', 'FC6', 'T8'],\n",
    "                 'Posterior' : ['CP5', 'P3', 'P7', 'CP6', 'P4', 'P8']}\n",
    "\n",
    "savefinal_folder = 'Results/LABS-LEISURE/'\n",
    "\n",
    "exp_folder = ['LABS-LEISURE/Eyes Closed/LEISURE', 'LABS-LEISURE/Eyes Closed/LABS']\n",
    "exp_condition = ['LEISURE', 'LABS']\n",
    "\n",
    "savefig = True\n",
    "freq_range = [1, 30]\n",
    "plot_titles = False\n",
    "\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the master files of EEG parameters and PSDs + check for normal distribution for all four parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the final datasets for the measures and PSDs\n",
    "df_wo_bads = pd.read_excel('{}/specparam_{}.xlsx'.format(savefinal_folder, str(exp_condition)), index_col=0)\n",
    "df_psd_wo_bads = pd.read_excel('{}/powerspectra_{}.xlsx'.format(savefinal_folder, str(exp_condition)), index_col=0)\n",
    "df_demo_cog = pd.read_excel('{}/demo_PAL_{}.xlsx'.format(savefinal_folder, str(exp_condition)), index_col=0)\n",
    "\n",
    "# Get the sample size for both groups\n",
    "print('Sample sizes:')\n",
    "print('LEISURE =', int(len(df_wo_bads[df_wo_bads['Group']=='LEISURE'].index)/len(df_wo_bads['Region'].unique())))\n",
    "print('LABS =', int(len(df_wo_bads[df_wo_bads['Group']=='LABS'].index)/len(df_wo_bads['Region'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normal_group(data, measure, region_col=None, group_col='Group', method='shapiro'):\n",
    "    \"\"\"\n",
    "    Check for normality within a dataframe for a specific measure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A long-format dataframe with required region and group columns\n",
    "    measure: A string for the column in the data to check normality for\n",
    "    method: A string for the normality test (see SciPy/Pingouin docs for tests)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    measure_norm: A dataframe of the normality tests results\n",
    "    \"\"\"\n",
    "    df_normalities = pd.DataFrame()\n",
    "    if region_col != None:\n",
    "        for region in data[region_col].unique():\n",
    "            df_normalities_temp = pg.normality(data[data[region_col]==region], dv=measure, group=group_col, method=method)\n",
    "            df_normalities_temp['Measure'] = measure\n",
    "            df_normalities_temp['Region'] = region\n",
    "            df_normalities = pd.concat([df_normalities, df_normalities_temp])\n",
    "    else:\n",
    "        df_normalities_temp = pg.normality(data, dv=measure, group=group_col, method=method)\n",
    "        df_normalities_temp['Measure'] = measure\n",
    "        df_normalities = pd.concat([df_normalities, df_normalities_temp])\n",
    "\n",
    "    measure_norm = df_normalities[df_normalities['Measure']==measure]\n",
    "\n",
    "    return measure_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for normality with Shapiro-Wilk test\n",
    "demo_pal_kwargs = dict(data=df_demo_cog, group_col='Group', method='shapiro')\n",
    "eeg_kwargs = dict(data=df_wo_bads, region_col='Region', group_col='Group', method='shapiro')\n",
    "\n",
    "print('\\nNormal distribution (Shapiro-Wilk):')\n",
    "for measure in ['Age', 'PAL Total Errors (Adjusted)']:\n",
    "    measure_norm = is_normal_group(measure=measure, **demo_pal_kwargs)\n",
    "    print('{} = {} / {}'.format(measure, measure_norm['normal'].sum(), measure_norm['normal'].count()))\n",
    "for measure in ['Exponent', 'Offset', 'Theta absolute power', 'Theta relative power']:\n",
    "    measure_norm = is_normal_group(measure=measure, **eeg_kwargs)\n",
    "    print('{} = {} / {}'.format(measure, measure_norm['normal'].sum(), measure_norm['normal'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add groups names to the demographics and PAL dataset\n",
    "df_demo_cog.loc[['HBA' in s for s in df_demo_cog.index], 'Group'] = 'LEISURE'\n",
    "df_demo_cog.loc[['LAB' in s for s in df_demo_cog.index], 'Group'] = 'LABS'\n",
    "\n",
    "for i, group in enumerate(exp_condition):\n",
    "    df_demo_cog_group = df_demo_cog[df_demo_cog['Group']==group]\n",
    "    if i == 0:\n",
    "        df_demo_cog_group_desc = df_demo_cog_group.describe()\n",
    "    else:\n",
    "        df_demo_cog_group_desc = pd.concat([df_demo_cog_group_desc, df_demo_cog_group.describe()],\n",
    "                                           axis=0, keys=exp_condition)\n",
    "\n",
    "    print('Females / Males ->', df_demo_cog_group['Sex (F)'].sum(), '/',\n",
    "          df_demo_cog_group['Sex (F)'].count()-df_demo_cog_group['Sex (F)'].sum())\n",
    "display(df_demo_cog_group_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = 'PAL Total Errors (Adjusted)'\n",
    "\n",
    "# Create a dataframe for the measure of interest\n",
    "df_pal = df_demo_cog[[measure, 'Group']]\n",
    "\n",
    "# Run stats for all the regions\n",
    "stats = pg.mwu(df_pal[df_pal['Group']=='LEISURE'][measure],\n",
    "               df_pal[df_pal['Group']=='LABS'][measure])\n",
    "display(stats)\n",
    "stats.to_excel('{}/comparison_stats_{}.xlsx'.format(savefinal_folder, measure))\n",
    "\n",
    "sns.set_context('notebook', font_scale=1)\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")\n",
    "swarm_kwargs = {'edgecolor' : 'gray', 'size' : 3, 'linewidth' : 0.9}\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(3, 4), dpi=100)\n",
    "sns.boxplot(ax=axs, data=df_pal, x='Group', y=measure, showfliers=False,\n",
    "            flierprops=dict(markerfacecolor = '0.5', markersize = 1),\n",
    "            order=['LEISURE', 'LABS'])\n",
    "sns.stripplot(ax=axs, data=df_pal, x='Group', y=measure,\n",
    "              dodge=True, order=['LEISURE', 'LABS'], **swarm_kwargs)\n",
    "axs.grid(linewidth=0.2)\n",
    "axs.set_xlabel('Group')\n",
    "axs.set_ylabel('PAL Total Errors (Adjusted)')\n",
    "axs.set_xticklabels(['Older Adults', 'Adolescents'])\n",
    "pairs=[(('LEISURE'), ('LABS'))]\n",
    "annotator = Annotator(axs, pairs=pairs, data=df_pal, x='Group', y=measure,\n",
    "                          plot=\"boxplot\")\\\n",
    "                .configure(test=None, text_format='star',loc='inside', verbose=1)\\\n",
    "                .set_pvalues(pvalues=stats['p-val']).annotate()\n",
    "plt.tight_layout()\n",
    "if savefig == True:\n",
    "    plt.savefig(fname='{}/{}.png'.format(savefinal_folder, measure), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aperiodic activity** plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aps_LEISURE = [None]*len(brain_regions)\n",
    "aps_LABS = [None]*len(brain_regions)\n",
    "df_aps_corr = pd.DataFrame()\n",
    "\n",
    "# Set plot styles\n",
    "aperiodicfit_kwargs = {'linewidth' : 1.25, 'alpha' : 0}\n",
    "aperiodicfit_psd_kwargs = {'linewidth' : 2, 'alpha' : 0.5, 'linestyle' : '--'}\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.4)\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 8), dpi=100)\n",
    "for i, region in enumerate(df_wo_bads['Region'].unique()):\n",
    "    # Choose only original PSDs and only the region of interest\n",
    "    df_psds = df_psd_wo_bads[df_psd_wo_bads['Type']=='powerspectra']\n",
    "    df_psds = df_psds[df_psds['Region']==region]\n",
    "\n",
    "    # Create regional original PSD files for both groups\n",
    "    df_psds_LEISURE = df_psds[df_psds['Group']=='LEISURE'].drop(columns=['Group', 'Type', 'Region'])\n",
    "    df_psds_LABS = df_psds[df_psds['Group']=='LABS'].drop(columns=['Group', 'Type', 'Region'])\n",
    "\n",
    "    # Grand average PSDs for both groups\n",
    "    freqs = df_psds_LEISURE.columns.to_numpy()\n",
    "    psd_mean_LEISURE = df_psds_LEISURE.mean(axis=0)\n",
    "    psd_mean_LABS = df_psds_LABS.mean(axis=0)\n",
    "\n",
    "    # Take only the region of interest for the aperiodic parameters in the df\n",
    "    df_aps_reg = df_wo_bads[['Offset','Exponent','Group']][df_wo_bads['Region']==region]\n",
    "\n",
    "    # Find Pearson's correlation between aperiodic parameters within groups and total sample size\n",
    "    for group in exp_condition:\n",
    "        df_aps_corr_temp = pg.corr(df_aps_reg[df_aps_reg['Group']==group]['Offset'],\n",
    "                                   df_aps_reg[df_aps_reg['Group']==group]['Exponent'])\n",
    "        df_aps_corr_temp['Group'] = group\n",
    "        df_aps_corr_temp['Region'] = region\n",
    "        df_aps_corr = pd.concat([df_aps_corr, df_aps_corr_temp])\n",
    "    df_aps_corr_total_temp = pg.corr(df_aps_reg['Offset'], df_aps_reg['Exponent'])\n",
    "    df_aps_corr_total_temp['Group'] = 'both'\n",
    "    df_aps_corr_total_temp['Region'] = region\n",
    "    df_aps_corr = pd.concat([df_aps_corr, df_aps_corr_total_temp])\n",
    "\n",
    "    # Convert the offset and exponent for both groups to 2D arrays\n",
    "    aps_LEISURE[i] = df_aps_reg[df_aps_reg['Group']=='LEISURE'].drop(columns='Group').values\n",
    "    aps_LABS[i] = df_aps_reg[df_aps_reg['Group']=='LABS'].drop(columns='Group').values\n",
    "\n",
    "    # Set the row and column for the subplots\n",
    "    row=0\n",
    "    col=i\n",
    "    if col>=3:\n",
    "        col-=3\n",
    "        row+=2\n",
    "    \n",
    "    # Plot the aperiodic component with the original PSD\n",
    "    plot_spectrum(freqs, psd_mean_LEISURE, ax=axs[row][col],\n",
    "                  plot_style=None, **aperiodicfit_psd_kwargs)\n",
    "    plot_spectrum(freqs, psd_mean_LABS, ax=axs[row][col],\n",
    "                  plot_style=None, **aperiodicfit_psd_kwargs)\n",
    "    plot_aperiodic_fits([aps_LEISURE[i], aps_LABS[i]], log_freqs=False,\n",
    "                        ax=axs[row][col], freq_range=freq_range, plot_style=None,\n",
    "                        labels=exp_condition, **aperiodicfit_kwargs)\n",
    "    axs[row][col].grid(linewidth=0.2)\n",
    "    axs[row][col].set_xlabel('Frequency (Hz)')\n",
    "    axs[row][col].set_ylabel('Log-normalised power')\n",
    "    #axs[row][col].legend()\n",
    "    axs[row][col].set_title('{} region'.format(region), fontweight='bold')\n",
    "\n",
    "    # Plot the aperiodic component parameters (exponent and offset)\n",
    "    sns.regplot(ax=axs[row+1][col], data=df_aps_reg[df_aps_reg['Group']=='LEISURE'], x='Offset', y='Exponent',\n",
    "                fit_reg=False, ci=None)\n",
    "    sns.regplot(ax=axs[row+1][col], data=df_aps_reg[df_aps_reg['Group']=='LABS'], x='Offset', y='Exponent',\n",
    "                fit_reg=False, ci=None)\n",
    "    sns.regplot(ax=axs[row+1][col], data=df_aps_reg, x='Offset', y='Exponent', scatter=False,\n",
    "                ci=None, color='gray', line_kws=dict(linestyle='--'))\n",
    "    axs[row+1][col].grid(linewidth=0.2)\n",
    "    axs[row+1][col].set_xlabel('Offset')\n",
    "    axs[row+1][col].set_ylabel('Exponent')\n",
    "\n",
    "    rval = float(df_aps_corr_total_temp['r'])\n",
    "    pval = float(df_aps_corr_total_temp['p-val'])\n",
    "    axs[row+1][col].text(.05, .9, f'r={rval:.2f}, p={pval:.2g}', transform=axs[row+1][col].transAxes,\n",
    "                         fontdict=dict(fontsize='small'))\n",
    "    plt.tight_layout()\n",
    "\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "legend = fig.legend(lines[0:2], ['Older Adults', 'Adolescents'], loc='upper center', bbox_to_anchor=(0,0.03,1,1), frameon=False, ncol=2)\n",
    "\n",
    "if savefig == True:\n",
    "    plt.savefig(fname='{}/aperiodic_plot.png'.format(savefinal_folder), bbox_inches='tight', bbox_extra_artists=[legend], dpi=300)\n",
    "plt.show()\n",
    "\n",
    "df_aps_corr = df_aps_corr.sort_values(by=['r'])\n",
    "df_aps_corr.to_excel('{}/aperiodic_correlations.xlsx'.format(savefinal_folder))\n",
    "display(df_aps_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")\n",
    "swarm_kwargs = {'edgecolor' : 'gray', 'size' : 2, 'linewidth' : 0, 'alpha' : 1}\n",
    "point_kwargs = {'markers' : ['o', 'o'], 'linestyles' : [' ', ' '], 'errwidth' : 2,\n",
    "                'capsize' : 0.1}\n",
    "meanprop_kwargs = {'marker' : 'D', 'markeredgecolor' : 'black', 'markersize' : 5,\n",
    "                   'markerfacecolor' : 'gray', 'label' : 'Mean'}\n",
    "\n",
    "df_aps = df_wo_bads[['Exponent', 'Offset', 'Region', 'Group']]\n",
    "measures = ['Exponent', 'Offset']\n",
    "post_hoc = 'Bonferroni'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 4), dpi=100)\n",
    "for i, ap in enumerate(measures):\n",
    "    # Run stats for all the regions // MAKE THIS STATS FUNCTION !!!!\n",
    "    df_stats = pd.DataFrame()\n",
    "    df_ap_desc = pd.DataFrame()\n",
    "    for j, region in enumerate(df_aps['Region'].unique()): # enumerate is not necessary!\n",
    "        # Do Welch's t-test test (parametric, independent groups but unequal sample sizes) between two groups\n",
    "        df_aps_reg = df_aps[df_aps['Region']==region].drop(columns=['Region'])\n",
    "        stats = pg.ttest(df_aps_reg[df_aps_reg['Group']==exp_condition[0]][ap],\n",
    "                        df_aps_reg[df_aps_reg['Group']==exp_condition[1]][ap])\n",
    "        \n",
    "        # Descriptive stats MAKE SURE TO HAVE OFFSET NOT OVERLAYING THE EXPONENT\n",
    "        df_ap_desc_temp = pd.concat([df_aps_reg[df_aps_reg['Group']==exp_condition[0]][ap].describe(),\n",
    "                                df_aps_reg[df_aps_reg['Group']==exp_condition[1]][ap].describe()],\n",
    "                                axis=0, keys=exp_condition).rename(region+' '+ap)\n",
    "        df_ap_desc = pd.concat([df_ap_desc, df_ap_desc_temp], axis=1)\n",
    "        \n",
    "        # Apply Bonferroni post-hoc multiple comparisons correction\n",
    "        if post_hoc == 'Bonferroni':\n",
    "            stats['p-val'] = stats['p-val']*len(df_aps['Region'].unique())\n",
    "            stats['Post-hoc'] = post_hoc\n",
    "        else:\n",
    "            stats['Post-hoc'] = 'N/A'\n",
    "        \n",
    "        stats['Groups'] = str(exp_condition)\n",
    "        stats['Region'] = region\n",
    "        stats['Measure'] = ap\n",
    "\n",
    "        df_stats = pd.concat([df_stats, stats])\n",
    "    print('\\n---\\n{} descriptives and comparison stats:'.format(ap))\n",
    "    display(df_ap_desc)\n",
    "    df_ap_desc.to_excel('{}/comparison_descriptives_{}.xlsx'.format(savefinal_folder, ap))\n",
    "    display(df_stats)\n",
    "    df_stats.to_excel('{}/comparison_stats_{}.xlsx'.format(savefinal_folder, ap))\n",
    "\n",
    "    sns.boxplot(ax=axs[i], data=df_aps, x='Region', y=ap, hue='Group',\n",
    "                showmeans=True, meanprops=meanprop_kwargs, palette='muted',\n",
    "                medianprops={'visible': False}, whiskerprops={'visible': False},\n",
    "                showfliers=False, showbox=False, showcaps=False)\n",
    "    sns.stripplot(ax=axs[i], data=df_aps, x='Region', y=ap, hue='Group',\n",
    "                  dodge=True, jitter=0.05, zorder=0, **swarm_kwargs)\n",
    "    axs[i].set_yscale('linear')\n",
    "    axs[i].grid(linewidth=0.2)\n",
    "    axs[i].set_xlabel('Region')\n",
    "    axs[i].set_ylabel(ap)\n",
    "    pairs=[\n",
    "        (('Frontal', 'LEISURE'), ('Frontal', 'LABS')),\n",
    "        (('Posterior', 'LEISURE'), ('Posterior', 'LABS')),\n",
    "        (('Temporal', 'LEISURE'), ('Temporal', 'LABS'))]\n",
    "    annotator = Annotator(axs[i], pairs=pairs, data=df_aps, x='Region', y=ap, hue='Group',\n",
    "                            plot=\"boxplot\", verbose=False)\\\n",
    "                    .configure(test=None, text_format='star',loc='inside', verbose=1)\\\n",
    "                    .set_pvalues(pvalues=df_stats['p-val']).annotate()\n",
    "    axs[i].get_legend().remove()\n",
    "    axs[i].set_xticklabels(['Frontal', 'Posterior', 'Temporal'])\n",
    "handles, _ = axs[i].get_legend_handles_labels()\n",
    "new_handles = [h for h in handles if isinstance(h, PathCollection)] + [h for h in handles if isinstance(h, Line2D)][:1]\n",
    "legend = fig.legend(handles=new_handles, labels=['Older Adults', 'Adolescents', 'Mean'], loc='upper center',\n",
    "           bbox_to_anchor=(0,0.07,1,1), frameon=False, ncol=3)\n",
    "plt.tight_layout()\n",
    "if savefig == True:\n",
    "    plt.savefig(fname='{}/exponent_offset.png'.format(savefinal_folder), bbox_extra_artists=[legend,],\n",
    "                bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theta absolute band power** plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theta stats and descriptives still need to-do for exporting to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_hoc = 'Bonferroni'\n",
    "measure = 'Theta absolute power'\n",
    "\n",
    "# Create a dataframe for the measure of interest\n",
    "df_powers = df_wo_bads[[measure, 'Region', 'Group']]\n",
    "\n",
    "# Run stats for all the regions\n",
    "df_stats = pd.DataFrame()\n",
    "for i, region in enumerate(df_wo_bads['Region'].unique()):\n",
    "    # Do Mann-Whitney U test (non-parametric, independent groups) between two groups\n",
    "    df_powers_reg = df_powers[df_powers['Region']==region].drop(columns=['Region'])\n",
    "    stats = pg.mwu(df_powers_reg[df_powers_reg['Group']==exp_condition[0]][measure],\n",
    "                   df_powers_reg[df_powers_reg['Group']==exp_condition[1]][measure])\n",
    "\n",
    "    # Apply Bonferroni post-hoc multiple comparisons correction\n",
    "    if post_hoc == 'Bonferroni':\n",
    "        stats['p-val'] = stats['p-val']*len(df_wo_bads['Region'].unique())\n",
    "        stats['Post-hoc'] = post_hoc\n",
    "    else:\n",
    "        stats['Post-hoc'] = 'N/A'\n",
    "    \n",
    "    stats['Groups'] = str(exp_condition)\n",
    "    stats['Region'] = region\n",
    "    stats['Measure'] = measure\n",
    "\n",
    "    df_stats = pd.concat([df_stats, stats])\n",
    "display(df_stats)\n",
    "\n",
    "swarm_kwargs = {'edgecolor' : 'gray', 'size' : 3, 'linewidth' : 0.9}\n",
    "sns.set_context('notebook')\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10, 4), dpi=100)\n",
    "sns.boxplot(ax=axs, data=df_powers,\n",
    "            x='Region', y=measure, hue='Group', showfliers=False,\n",
    "            flierprops=dict(markerfacecolor = '0.5', markersize = 1))\n",
    "sns.stripplot(ax=axs, data=df_powers, x='Region', y=measure, hue='Group',\n",
    "              dodge=True, **swarm_kwargs)\n",
    "axs.set_yscale('log')\n",
    "axs.grid(linewidth=0.2)\n",
    "axs.set_xlabel('Region')\n",
    "axs.set_ylabel('Absolute power (µV\\u00b2/Hz)')\n",
    "pairs=[(('Frontal', 'LEISURE'), ('Frontal', 'LABS')),\n",
    "        (('Posterior', 'LEISURE'), ('Posterior', 'LABS')),\n",
    "        (('Temporal', 'LEISURE'), ('Temporal', 'LABS'))]\n",
    "annotator = Annotator(axs, pairs=pairs, data=df_powers, x='Region', y=measure, hue='Group',\n",
    "                          plot=\"boxplot\")\\\n",
    "                .configure(test=None, text_format='star',loc='inside', verbose=1)\\\n",
    "                .set_pvalues(pvalues=df_stats['p-val']).annotate()\n",
    "\n",
    "if plot_titles==True: (axs.set_title('Theta absolute band power'))\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles[0:2], labels[0:2])\n",
    "plt.tight_layout()\n",
    "if savefig == True:\n",
    "    plt.savefig(fname='{}/absolute_theta.png'.format(savefinal_folder), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theta relative band power** plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_hoc = 'Bonferroni'\n",
    "measure = 'Theta relative power'\n",
    "\n",
    "# Create a dataframe for the measure of interest\n",
    "df_powers = df_wo_bads[[measure, 'Region', 'Group']]\n",
    "\n",
    "# Run stats for all the regions\n",
    "df_stats = pd.DataFrame()\n",
    "for i, region in enumerate(df_wo_bads['Region'].unique()):\n",
    "    # Do Mann-Whitney U test (non-parametric, independent groups) between two groups\n",
    "    df_powers_reg = df_powers[df_powers['Region']==region].drop(columns=['Region'])\n",
    "    stats = pg.mwu(df_powers_reg[df_powers_reg['Group']==exp_condition[0]][measure],\n",
    "                   df_powers_reg[df_powers_reg['Group']==exp_condition[1]][measure])\n",
    "\n",
    "    # Apply Bonferroni post-hoc multiple comparisons correction\n",
    "    if post_hoc == 'Bonferroni':\n",
    "        stats['p-val'] = stats['p-val']*len(df_wo_bads['Region'].unique())\n",
    "        stats['Post-hoc'] = post_hoc\n",
    "    else:\n",
    "        stats['Post-hoc'] = 'N/A'\n",
    "    \n",
    "    stats['Groups'] = str(exp_condition)\n",
    "    stats['Region'] = region\n",
    "    stats['Measure'] = measure\n",
    "\n",
    "    df_stats = pd.concat([df_stats, stats])\n",
    "display(df_stats)\n",
    "\n",
    "swarm_kwargs = {'edgecolor' : 'gray', 'size' : 3, 'linewidth' : 0.9}\n",
    "sns.set_context('notebook')\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10, 4), dpi=100)\n",
    "sns.boxplot(ax=axs, data=df_powers,\n",
    "            x='Region', y=measure, hue='Group', showfliers=False,\n",
    "            flierprops=dict(markerfacecolor = '0.5', markersize = 1))\n",
    "sns.stripplot(ax=axs, data=df_powers, x='Region', y=measure, hue='Group',\n",
    "              dodge=True, **swarm_kwargs)\n",
    "axs.set_yscale('linear')\n",
    "axs.grid(linewidth=0.2)\n",
    "axs.set_xlabel('Region')\n",
    "axs.set_ylabel('Relative power')\n",
    "pairs=[(('Frontal', 'LEISURE'), ('Frontal', 'LABS')),\n",
    "        (('Posterior', 'LEISURE'), ('Posterior', 'LABS')),\n",
    "        (('Temporal', 'LEISURE'), ('Temporal', 'LABS'))]\n",
    "annotator = Annotator(axs, pairs=pairs, data=df_powers, x='Region', y=measure, hue='Group',\n",
    "                          plot=\"boxplot\")\\\n",
    "                .configure(test=None, text_format='star',loc='inside', verbose=1)\\\n",
    "                .set_pvalues(pvalues=df_stats['p-val']).annotate()\n",
    "\n",
    "if plot_titles==True: (axs[1].set_title('Theta relative band power'))\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles[0:2], labels[0:2])\n",
    "plt.tight_layout()\n",
    "if savefig == True:\n",
    "    plt.savefig(fname='{}/relative_theta.png'.format(savefinal_folder), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIERARCHICAL LINEAR REGRESSION ANALYSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the final datasets for the measures and PSDs\n",
    "df_wo_bads = pd.read_excel('{}/specparam_{}.xlsx'.format(savefinal_folder, str(exp_condition)), index_col=0)\\\n",
    "               .drop(columns=['R_2', 'Error'])\n",
    "df_demo_cog = pd.read_excel('{}/demo_PAL_{}.xlsx'.format(savefinal_folder, str(exp_condition)), index_col=0)\\\n",
    "                .drop(columns=['Group'])\n",
    "\n",
    "regions = df_wo_bads['Region'].unique()\n",
    "groups = df_wo_bads['Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = 'Offset'\n",
    "outcome = 'PAL Total Errors (Adjusted)'\n",
    "diagnostics = False\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for r, region in enumerate(regions):\n",
    "\n",
    "    # Concatenate demographics/PAL data with EEG measures for the region of the interest\n",
    "    data = pd.concat([df_wo_bads[df_wo_bads['Region']==region], df_demo_cog], axis=1)\n",
    "\n",
    "    # Run HLR for both groups\n",
    "    results_grp = pd.DataFrame()\n",
    "    for g, group in enumerate(groups):\n",
    "        if diagnostics ==True: print('\\n\\n--------------------\\nHierarchical regression -',predictor,'predicting',outcome,'@',region,'for',group)\n",
    "\n",
    "        grp_data = data[data['Group']==group]\n",
    "\n",
    "        # List of dataframes of predictor variables for each step\n",
    "        X = [grp_data[['Age', 'Sex (F)']],\n",
    "             grp_data[['Age', 'Sex (F)', predictor]]]\n",
    "\n",
    "        # List of predictor variable names for each step\n",
    "        X_names = [['Age', 'Sex'], \n",
    "                   ['Age', 'Sex', predictor]]\n",
    "\n",
    "        # Outcome variable as dataframe\n",
    "        y = grp_data[[outcome]]\n",
    "\n",
    "        # Create a HLR model with diagnostic tests, run and save the results\n",
    "        model = HLR.HLR_model(diagnostics=diagnostics, showfig=True, save_folder='results/{}'.format(predictor), verbose=True)\n",
    "        results_temp, reg_models = model.run(X=X, X_names=X_names, y=y)\n",
    "        #model.save_results(filename='labs-leisure_results', show_results=True)\n",
    "    \n",
    "        # Modify the results dataframe by adding region and outcome measure and concat to master dataframe\n",
    "        results_temp['Group'] = group\n",
    "        results_temp['Region'] = region\n",
    "        results_temp['Outcome measure'] = outcome\n",
    "        results_temp['Predictor of interest'] = predictor\n",
    "        results_grp = pd.concat([results_grp, results_temp]).reset_index(drop=True)\n",
    "    results = pd.concat([results, results_grp]).reset_index(drop=True)\n",
    "\n",
    "display(results)\n",
    "try:\n",
    "    os.makedirs('{}/HLR/{}/'.format(savefinal_folder, predictor))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "results.to_excel('{}/HLR/{}/HLR_results_predictor={}_outcome={}.xlsx'.format(savefinal_folder,\n",
    "                                                                             predictor,\n",
    "                                                                             predictor,\n",
    "                                                                             outcome))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40b6f1921e299bbf3a05af3ad742995027eacf5242faafa5dd2eecd335e75046"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
