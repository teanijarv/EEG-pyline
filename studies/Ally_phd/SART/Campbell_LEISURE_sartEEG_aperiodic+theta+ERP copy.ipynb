{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Working Title]\n",
    "\n",
    "Created by Toomas Erik AnijÃ¤rv in 25.05.2023\n",
    "\n",
    "This notebook is a representation of EEG processing done for the publication with one of the participants as an example.\n",
    "\n",
    "You are free to use this or any other code from this repository for your own projects and publications. Citation or reference to the repository is not required, but would be much appreciated (see more on README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import mne, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "from autoreject import (get_rejection_threshold, AutoReject)\n",
    "from fooof import FOOOF\n",
    "from fooof.plts.spectra import plot_spectrum, plot_spectrum_shading\n",
    "\n",
    "# Set the default directory\n",
    "os.chdir('/Users/tanijarv/Documents/GitHub/EEG-pyline')\n",
    "mne.set_log_level('error')\n",
    "\n",
    "# Import functions\n",
    "import basic.arrange_data as arrange\n",
    "import signal_processing.pre_process as prep\n",
    "import signal_processing.spectral_analysis as spectr\n",
    "import signal_processing.erp_analysis as erpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where to get the raw EEG files\n",
    "raw_folder = 'Data/Raw/'\n",
    "\n",
    "# Folder where to export the clean epochs files\n",
    "clean_folder = 'Data/Clean/'\n",
    "\n",
    "# Folder where to save the results and plots\n",
    "results_folder = 'Results/'\n",
    "\n",
    "# Sub-folder for the experiment (i.e. timepoint or group)\n",
    "exp_folder = 'LEISURE/T1/SART/'\n",
    "exp_condition = 'SART_T1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING & TASK PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOG + mastoid channels and stimulus channel\n",
    "eog_channels = ['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8']\n",
    "stimulus_channel = 'Status'\n",
    "\n",
    "# Parameters for filter design\n",
    "filter_design = dict(l_freq=1, h_freq=30, filter_length='auto', method='fir',\n",
    "                     l_trans_bandwidth='auto', h_trans_bandwidth='auto',\n",
    "                     phase='zero', fir_window='hamming', fir_design='firwin')\n",
    "\n",
    "# Epoch time window from event/stimuli\n",
    "tminmax = [-0.2, 1]\n",
    "\n",
    "# Baseline correction time window\n",
    "baseline_correction = None\n",
    "\n",
    "# Event names with IDs for GO and NO-GO trials\n",
    "event_dict = {'GO trial': 4,\n",
    "              'NO-GO trial': 8,\n",
    "              'Button press': 16}\n",
    "\n",
    "# Button press ID\n",
    "button_id = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directories of raw EEG files and set export directory for clean files\n",
    "dir_inprogress = os.path.join(raw_folder,exp_folder)\n",
    "export_dir = os.path.join(clean_folder,exp_folder)\n",
    "file_dirs, subject_names = arrange.read_files(dir_inprogress,'.bdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the subjects' directories (EEG files directories)\n",
    "df_success = pd.DataFrame()\n",
    "for i in range(len(file_dirs)):\n",
    "        print('\\n{} ({} / {})'.format(subject_names[i], i+1, len(file_dirs)))\n",
    "        # Read in the raw EEG data\n",
    "        try:\n",
    "                raw = mne.io.read_raw_bdf(file_dirs[i], infer_types=True, eog=eog_channels,\n",
    "                                        stim_channel=stimulus_channel).drop_channels(['Erg1'])\n",
    "        except:\n",
    "                raw = mne.io.read_raw_bdf(file_dirs[i], infer_types=True, eog=eog_channels,\n",
    "                                        stim_channel=stimulus_channel)\n",
    "\n",
    "        # Set the right montage (Biosemi32) and set reference as average across all channels\n",
    "        raw = raw.set_montage(mne.channels.make_standard_montage('biosemi32')).load_data()\\\n",
    "                 .set_eeg_reference(ref_channels='average', verbose=False)\n",
    "    \n",
    "        # Filter the signal with bandpass filter and remove EOG artefacts with SSP\n",
    "        filt = prep.filter_raw_data(raw, filter_design, line_remove=None, eog_channels=eog_channels,\n",
    "                                    plot_filt=False, savefig=False, verbose=False)\n",
    "        \n",
    "        # Find events from the filtered EEG data and name them\n",
    "        events = mne.find_events(filt, stim_channel=stimulus_channel, consecutive=False, output='onset')\n",
    "        \n",
    "        # Create an array and dataframe of successful GO (followed with button press) and NO-GO trials (no button press)\n",
    "        success_events_total = []\n",
    "        success_go = []\n",
    "        unsuccess_nogo = []\n",
    "        df_success_temp = pd.DataFrame(index=[subject_names[i]],\n",
    "                                       data={'Total GO' : np.sum(events[:, 2] == event_dict['GO trial']),\n",
    "                                             'Total NO-GO' : np.sum(events[:, 2] == event_dict['NO-GO trial']),\n",
    "                                             'Correct GO': 0, 'Correct NO-GO': 0,\n",
    "                                             'Incorrect GO': 0, 'Incorrect NO-GO': 0})\n",
    "        # Go through all events to check if they were successful or not\n",
    "        for m in range(len(events)):\n",
    "                # If event is a GO, check for button press\n",
    "                if events[m][2] == event_dict['GO trial']:\n",
    "                        if events[m+1][2] == button_id:\n",
    "                                # If there is a button press -> success\n",
    "                                success_events_total.append(events[m])\n",
    "                                success_events_total.append(events[m+1])\n",
    "                                success_go.append(events[m])\n",
    "                                success_go.append(events[m+1])\n",
    "                                df_success_temp['Correct GO'] += 1\n",
    "                        else:\n",
    "                                # If there is no button press -> fail\n",
    "                                df_success_temp['Incorrect GO'] += 1\n",
    "                # If event is a NO-GO, check for no button press\n",
    "                if events[m][2] == event_dict['NO-GO trial']:\n",
    "                        if events[m+1][2] != button_id:\n",
    "                                # If there is no button press -> success\n",
    "                                success_events_total.append(events[m])\n",
    "                                df_success_temp['Correct NO-GO'] += 1\n",
    "                        else:\n",
    "                                # If there is a button press -> fail\n",
    "                                unsuccess_nogo.append(events[m])\n",
    "                                unsuccess_nogo.append(events[m+1])\n",
    "                                df_success_temp['Incorrect NO-GO'] += 1\n",
    "        success_events_total = np.asarray(success_events_total)\n",
    "        success_go = np.asarray(success_go)\n",
    "        unsuccess_nogo = np.asarray(unsuccess_nogo)\n",
    "\n",
    "        # Calculate response times to button press for correct GO and incorrect NO-GO\n",
    "        if len(success_go)!=0:\n",
    "                rt_go = np.diff(success_go[:, 0])[0::2]/raw.info['sfreq']\n",
    "        else:\n",
    "                rt_go = 0\n",
    "        if len(unsuccess_nogo)!=0:\n",
    "                rt_nogo = np.diff(unsuccess_nogo[:, 0])[0::2]/raw.info['sfreq']\n",
    "        else:\n",
    "                rt_nogo = 0\n",
    "\n",
    "        # Calculate descriptives for these response times\n",
    "        df_success_temp['Average RT (Correct GO)'] = np.mean(rt_go)\n",
    "        df_success_temp['Average RT (Incorrect NO-GO)'] = np.mean(rt_nogo)\n",
    "        df_success_temp['SD RT (Correct GO)'] = np.std(rt_go)\n",
    "        df_success_temp['SD RT (Incorrect NO-GO)'] = np.std(rt_nogo)\n",
    "        df_success_temp['Median RT (Correct GO)'] = np.median(rt_go)\n",
    "        df_success_temp['Median RT (Incorrect NO-GO)'] = np.median(rt_nogo)\n",
    "        df_success_temp['Minimum RT (Correct GO)'] = np.min(rt_go)\n",
    "        df_success_temp['Minimum RT (Incorrect NO-GO)'] = np.min(rt_nogo)\n",
    "        df_success_temp['Maximum RT (Correct GO)'] = np.max(rt_go)\n",
    "        df_success_temp['Maximum RT (Incorrect NO-GO)'] = np.max(rt_nogo)\n",
    "        df_success_temp['RTs (Correct GO)'] = str(rt_go)\n",
    "        df_success_temp['RTs (Incorrect NO-GO)'] = str(rt_nogo)\n",
    "\n",
    "        # Merge the participant dataframe with the master dataframe\n",
    "        df_success = pd.concat([df_success, df_success_temp])\n",
    "\n",
    "        # Plot all the events\n",
    "        %matplotlib inline\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        fig = mne.viz.plot_events(success_events_total, sfreq=filt.info['sfreq'],\n",
    "                                  first_samp=filt.first_samp, event_id=event_dict,\n",
    "                                  axes=axs, show=False)\n",
    "        fig.subplots_adjust(right=0.7)\n",
    "        axs.set_title('Successful events ({})'.format(subject_names[i]))\n",
    "        plt.show()\n",
    "\n",
    "        # Create epochs time-locked to successful GO and NO-GO events (without including the button press events)\n",
    "        picks = mne.pick_types(filt.info, eeg=True, stim=False)\n",
    "        epochs = mne.Epochs(filt, success_events_total[success_events_total[:, 2] != 16], #event_id=event_dict,\n",
    "                            tmin=tminmax[0], tmax=tminmax[1], baseline=baseline_correction,\n",
    "                            picks=picks, preload=True)\n",
    "        \n",
    "        # Plot the epochs' GFP plot before artefact rejection\n",
    "        epochs.plot_image(title=\"GFP without AR ({})\".format(subject_names[i]))\n",
    "\n",
    "        # Use AutoReject to repair and remove epochs which are artefactual\n",
    "        reject_criteria = get_rejection_threshold(epochs)\n",
    "        print('Dropping epochs with rejection threshold:',reject_criteria)\n",
    "        epochs.drop_bad(reject=reject_criteria)\n",
    "\n",
    "        ar = AutoReject(thresh_method='random_search', random_state=1)\n",
    "        ar.fit(epochs)\n",
    "        epochs_ar, reject_log = ar.transform(epochs, return_log=True)\n",
    "        reject_log.plot('horizontal')\n",
    "\n",
    "        # Plot the epochs' GFP after artefact rejection\n",
    "        epochs_ar.average().plot()\n",
    "        epochs_ar.plot_image(title=\"GFP with AR ({})\".format(subject_names[i]))\n",
    "\n",
    "        # Display the final epochs object meta-data\n",
    "        display(epochs_ar)\n",
    "\n",
    "        # Save the cleaned EEG file as .fif file\n",
    "        try:\n",
    "                os.makedirs(export_dir)\n",
    "        except FileExistsError:\n",
    "                pass\n",
    "        try:\n",
    "                mne.Epochs.save(epochs_ar, fname='{}/{}_clean-epo.fif'.format(export_dir,\n",
    "                                                                              subject_names[i]),\n",
    "                                                                              overwrite=True)\n",
    "        except FileExistsError:\n",
    "                pass\n",
    "        \n",
    "# Save the dataframe for task performance\n",
    "df_success.to_excel('{}/{}/{}_task_performance.xlsx'.format(results_folder,exp_folder,exp_condition))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECTRAL ANALYSIS: APERIODIC + THETA ACTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain regions and their channels /// do for Fz, Cz, Pz\n",
    "ch = 'Pz'\n",
    "\n",
    "# Power spectra estimation parameters\n",
    "psd_params = dict(method='welch', fminmax=[1, 30], window='hamming', window_duration=1,\n",
    "                  window_overlap=0, zero_padding=3, tminmax=[0, 1])\n",
    "\n",
    "# FOOOF (specparam) model parameters\n",
    "fooof_params = dict(peak_width_limits=[1,12], max_n_peaks=float('inf'), min_peak_height=0.225,\n",
    "                    peak_threshold=2.0, aperiodic_mode='fixed')\n",
    "\n",
    "# Band power of interest\n",
    "bands = {'Theta' : [4, 8]}\n",
    "\n",
    "# Flattened spectra amplitude scale (linear, log)\n",
    "flat_spectr_scale = 'linear'\n",
    "\n",
    "# Plot more information on the model fit plots or not; and save these plots or not\n",
    "plot_rich = True\n",
    "savefig = True\n",
    "\n",
    "# Event names (i.e. different stimuli) within the epochs\n",
    "event_list = ['GO trial', 'NO-GO trial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directories of clean EEG files and set export directory\n",
    "dir_inprogress = os.path.join(clean_folder, exp_folder)\n",
    "file_dirs, subject_names = arrange.read_files(dir_inprogress, \"_clean-epo.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-create results folders and dataframe\n",
    "arrange.create_results_folders(exp_folder=exp_folder, results_folder=results_folder, fooof=True)\n",
    "df_ch = pd.DataFrame()\n",
    "# Go through all the files (subjects) in the folder\n",
    "for i in range(len(file_dirs)):\n",
    "    # Read the clean data from the disk\n",
    "    epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress, subject_names[i]),\n",
    "                                                                verbose=False)\n",
    "\n",
    "    # Loop through all different events\n",
    "    df_ch_ev = pd.DataFrame()\n",
    "    df_ch_ev_diff = pd.DataFrame()\n",
    "    for ev in event_list:\n",
    "        print('{} for {} ({}/{})'.format(ev, subject_names[i], i+1, len(file_dirs)))\n",
    "\n",
    "        ### POST-EVENT PSD ESTIMATION\n",
    "\n",
    "        # Choose only epochs from the current event\n",
    "        epochs_ev = epochs[ev]\n",
    "\n",
    "        # Calculate Welch's power spectrum density (FFT) for the mean post-event\n",
    "        [psds, freqs] = spectr.calculate_psd(epochs_ev, subject_names[i], **psd_params, verbose=True, plot=False)\n",
    "        \n",
    "        # Average all epochs and channels together -> (freq bins,) shape\n",
    "        if i == 0:\n",
    "            psds_allch = np.zeros(shape=(len(file_dirs), len(freqs)))\n",
    "        psds_allch[i] = psds.mean(axis=(0, 1))\n",
    "\n",
    "        # Average all epochs together for each channel and also for each region\n",
    "        psds = psds.mean(axis=(0))\n",
    "        df_psds_ch = arrange.array_to_df(subject_names[i], epochs_ev, psds).\\\n",
    "                            reset_index().drop(columns='Subject')\n",
    "\n",
    "        # Choose only channel of interest data\n",
    "        psds_temp = df_psds_ch[ch].to_numpy()\n",
    "\n",
    "        ### ERP & POST-minus-ERP PSD ESTIMATIONS\n",
    "\n",
    "        # Average the event epochs in time domain\n",
    "        evoked_ev = epochs_ev.average(picks=ch)\n",
    "\n",
    "        # Calculate Welch's power spectrum density (FFT) for the ERP\n",
    "        [psds_erp, freqs] = spectr.calculate_psd(evoked_ev, subject_names[i], **psd_params, verbose=True, plot=False)\n",
    "\n",
    "        # Calculate the post-minus-ERP PSD subtracting ERP PSD from post-event PSD\n",
    "        psds_diff_ch = psds_temp - psds_erp[0]\n",
    "\n",
    "        ### SPECPARAM\n",
    "\n",
    "        # Fit the spectrums with FOOOF\n",
    "        fm = FOOOF(**fooof_params, verbose=True)\n",
    "        fm.fit(freqs, psds_temp, psd_params['fminmax'])\n",
    "        fm_diff = FOOOF(**fooof_params, verbose=True)\n",
    "        fm_diff.fit(freqs, psds_diff_ch, psd_params['fminmax'])\n",
    "            \n",
    "        # Log-linear conversion based on the chosen amplitude scale\n",
    "        if flat_spectr_scale == 'linear':\n",
    "            flatten_spectrum = 10 ** fm._spectrum_flat\n",
    "            flatten_spectrum_diff = 10 ** fm_diff._spectrum_flat\n",
    "            flat_spectr_ylabel = 'Amplitude (uV\\u00b2/Hz)'\n",
    "        elif flat_spectr_scale == 'log':\n",
    "            flatten_spectrum = fm._spectrum_flat\n",
    "            flatten_spectrum_diff = fm_diff._spectrum_flat\n",
    "            flat_spectr_ylabel = 'Log-normalised amplitude'\n",
    "\n",
    "        # Find individual alpha band parameters\n",
    "        abs_bp, rel_bp = spectr.find_bp(flatten_spectrum, freqs, bands['Theta'])\n",
    "        abs_bp_diff, rel_bp_diff = spectr.find_bp(flatten_spectrum_diff, freqs, bands['Theta'])\n",
    "\n",
    "        ### PLOTTING\n",
    "\n",
    "        # Set plot styles\n",
    "        data_kwargs = {'color' : 'black', 'linewidth' : 1.4, 'label' : 'Original'}\n",
    "        model_kwargs = {'color' : 'red', 'linewidth' : 1.4, 'alpha' : 0.75, 'label' : 'Full model'}\n",
    "        aperiodic_kwargs = {'color' : 'blue', 'linewidth' : 1.4, 'alpha' : 0.75,\n",
    "                            'linestyle' : 'dashed', 'label' : 'Aperiodic model'}\n",
    "        flat_kwargs = {'color' : 'black', 'linewidth' : 1.4}\n",
    "        hvline_kwargs = {'color' : 'blue', 'linewidth' : 1.0, 'linestyle' : 'dashed', 'alpha' : 0.75}\n",
    "        \n",
    "        # Plot power spectrum model + aperiodic fit for MEAN POST-EVENT PSD\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), dpi=100)\n",
    "        plot_spectrum(fm.freqs, fm.power_spectrum,\n",
    "                    ax=axs[0], plot_style=None, **data_kwargs)\n",
    "        plot_spectrum(fm.freqs, fm.fooofed_spectrum_,\n",
    "                    ax=axs[0], plot_style=None, **model_kwargs)\n",
    "        plot_spectrum(fm.freqs, fm._ap_fit,\n",
    "                    ax=axs[0], plot_style=None, **aperiodic_kwargs)\n",
    "        axs[0].set_xlim(psd_params['fminmax'])\n",
    "        axs[0].grid(linewidth=0.2)\n",
    "        axs[0].set_xlabel('Frequency (Hz)')\n",
    "        axs[0].set_ylabel('Log-normalised power (log$_{10}$[ÂµV\\u00b2/Hz])')\n",
    "        axs[0].set_title('Spectrum model fit')\n",
    "        axs[0].legend()\n",
    "        \n",
    "        # Flattened spectrum plot (i.e., minus aperiodic fit)\n",
    "        plot_spectrum_shading(fm.freqs, flatten_spectrum,\n",
    "                    ax=axs[1], shades=bands['Theta'], shade_colors='green',\n",
    "                    plot_style=None, **flat_kwargs)\n",
    "        #axs[1].vlines(bands['Theta'], ymin=axs[1].get_ylim()[0], ymax=axs[1].get_ylim()[1])\n",
    "        axs[1].set_xlim(psd_params['fminmax'])\n",
    "        axs[1].grid(linewidth=0.2)\n",
    "        axs[1].set_xlabel('Frequency (Hz)')\n",
    "        axs[1].set_ylabel(flat_spectr_ylabel)\n",
    "        axs[1].set_title('Flattened spectrum')\n",
    "\n",
    "        # If true, plot all the exported variables on the plots\n",
    "        if plot_rich == True:\n",
    "            axs[0].annotate('Error: ' + str(np.round(fm.get_params('error'), 4)) +\n",
    "                        '\\nR\\u00b2: ' + str(np.round(fm.get_params('r_squared'), 4)),\n",
    "                        (0.1, 0.16), xycoords='figure fraction', color='red', fontsize=8.5)\n",
    "            axs[0].annotate('Exponent: ' + str(np.round(fm.get_params('aperiodic_params','exponent'), 4)) +\n",
    "                        '\\nOffset: ' + str(np.round(fm.get_params('aperiodic_params','offset'), 4)),\n",
    "                        (0.19, 0.16), xycoords='figure fraction', color='blue', fontsize=8.5)\n",
    "            axs[1].annotate('Absolute theta BP: '+str(np.round(abs_bp, 4))+'\\nRelative theta BP: '+str(np.round(rel_bp, 4)),\n",
    "                            (0.69, 0.16), xycoords='figure fraction', color='green', fontsize=8.5)\n",
    "        \n",
    "        plt.suptitle('Mean post-event PSD at {} ({})'.format(ch, subject_names[i]))\n",
    "        plt.tight_layout()\n",
    "        if savefig == True:\n",
    "            plt.savefig(fname='{}/{}/FOOOF/{}_{}_{}_mean_post_event_PSD.png'.format(results_folder, exp_folder,\n",
    "                                                                        exp_condition, subject_names[i],\n",
    "                                                                        ch), dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot power spectrum model + aperiodic fit for POST-minus-ERP PSD\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), dpi=100)\n",
    "        plot_spectrum(fm_diff.freqs, fm_diff.power_spectrum,\n",
    "                    ax=axs[0], plot_style=None, **data_kwargs)\n",
    "        plot_spectrum(fm_diff.freqs, fm_diff.fooofed_spectrum_,\n",
    "                    ax=axs[0], plot_style=None, **model_kwargs)\n",
    "        plot_spectrum(fm_diff.freqs, fm_diff._ap_fit,\n",
    "                    ax=axs[0], plot_style=None, **aperiodic_kwargs)\n",
    "        axs[0].set_xlim(psd_params['fminmax'])\n",
    "        axs[0].grid(linewidth=0.2)\n",
    "        axs[0].set_xlabel('Frequency (Hz)')\n",
    "        axs[0].set_ylabel('Log-normalised power (log$_{10}$[ÂµV\\u00b2/Hz])')\n",
    "        axs[0].set_title('Spectrum model fit')\n",
    "        axs[0].legend()\n",
    "        \n",
    "        # Flattened spectrum plot (i.e., minus aperiodic fit)\n",
    "        plot_spectrum_shading(fm_diff.freqs, flatten_spectrum_diff,\n",
    "                    ax=axs[1], shades=bands['Theta'], shade_colors='green',\n",
    "                    plot_style=None, **flat_kwargs)\n",
    "        #axs[1].vlines(bands['Theta'], ymin=axs[1].get_ylim()[0], ymax=axs[1].get_ylim()[1])\n",
    "        axs[1].set_xlim(psd_params['fminmax'])\n",
    "        axs[1].grid(linewidth=0.2)\n",
    "        axs[1].set_xlabel('Frequency (Hz)')\n",
    "        axs[1].set_ylabel(flat_spectr_ylabel)\n",
    "        axs[1].set_title('Flattened spectrum')\n",
    "\n",
    "        # If true, plot all the exported variables on the plots\n",
    "        if plot_rich == True:\n",
    "            axs[0].annotate('Error: ' + str(np.round(fm_diff.get_params('error'), 4)) +\n",
    "                        '\\nR\\u00b2: ' + str(np.round(fm_diff.get_params('r_squared'), 4)),\n",
    "                        (0.1, 0.16), xycoords='figure fraction', color='red', fontsize=8.5)\n",
    "            axs[0].annotate('Exponent: ' + str(np.round(fm_diff.get_params('aperiodic_params','exponent'), 4)) +\n",
    "                        '\\nOffset: ' + str(np.round(fm_diff.get_params('aperiodic_params','offset'), 4)),\n",
    "                        (0.19, 0.16), xycoords='figure fraction', color='blue', fontsize=8.5)\n",
    "            axs[1].annotate('Absolute theta BP: '+str(np.round(abs_bp_diff, 4))+'\\nRelative theta BP: '+str(np.round(rel_bp_diff, 4)),\n",
    "                            (0.69, 0.16), xycoords='figure fraction', color='green', fontsize=8.5)\n",
    "        \n",
    "        plt.suptitle('Post-minus-ERP PSD at {} ({})'.format(ch, subject_names[i]))\n",
    "        plt.tight_layout()\n",
    "        if savefig == True:\n",
    "            plt.savefig(fname='{}/{}/FOOOF/{}_{}_{}_post_minus_erp_PSD.png'.format(results_folder, exp_folder,\n",
    "                                                                        exp_condition, subject_names[i],\n",
    "                                                                        ch), dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        ### EXPORTING\n",
    "\n",
    "        # Add model parameters to dataframe for mean post-event\n",
    "        df_ch_ev.loc[i, 'Exponent'] = fm.get_params('aperiodic_params','exponent')\n",
    "        df_ch_ev.loc[i, 'Offset'] = fm.get_params('aperiodic_params','offset')\n",
    "        df_ch_ev.loc[i, '{} absolute power'.format(list(bands.keys())[0])] = abs_bp\n",
    "        df_ch_ev.loc[i, '{} relative power'.format(list(bands.keys())[0])] = rel_bp\n",
    "        df_ch_ev.loc[i, 'R_2'] = fm.get_params('r_squared')\n",
    "        df_ch_ev.loc[i, 'Error'] = fm.get_params('error')\n",
    "        df_ch_ev['Channel'] = ch\n",
    "        df_ch_ev['Event'] = ev\n",
    "        df_ch_ev['Type'] = 'Mean post-event'\n",
    "        df_ch_ev['Subject'] = subject_names[i]\n",
    "\n",
    "        # Concatenate to master dataframe for mean post-event\n",
    "        df_ch = pd.concat([df_ch, df_ch_ev])\n",
    "\n",
    "        # Add model parameters to dataframe for post-minus-erp\n",
    "        df_ch_ev_diff.loc[i, 'Exponent'] = fm_diff.get_params('aperiodic_params','exponent')\n",
    "        df_ch_ev_diff.loc[i, 'Offset'] = fm_diff.get_params('aperiodic_params','offset')\n",
    "        df_ch_ev_diff.loc[i, '{} absolute power'.format(list(bands.keys())[0])] = abs_bp_diff\n",
    "        df_ch_ev_diff.loc[i, '{} relative power'.format(list(bands.keys())[0])] = rel_bp_diff\n",
    "        df_ch_ev_diff.loc[i, 'R_2'] = fm_diff.get_params('r_squared')\n",
    "        df_ch_ev_diff.loc[i, 'Error'] = fm_diff.get_params('error')\n",
    "        df_ch_ev_diff['Channel'] = ch\n",
    "        df_ch_ev_diff['Event'] = ev\n",
    "        df_ch_ev_diff['Type'] = 'Post-minus-ERP'\n",
    "        df_ch_ev_diff['Subject'] = subject_names[i]\n",
    "\n",
    "        # Concatenate to master dataframe for post-minus-erp\n",
    "        df_ch = pd.concat([df_ch, df_ch_ev_diff])\n",
    "        \n",
    "\n",
    "# Reorder the channels and reset index\n",
    "df_ch = df_ch[['Subject', 'Channel', 'Type', 'Event', 'Exponent', 'Offset',\n",
    "               '{} absolute power'.format(list(bands.keys())[0]),\n",
    "               '{} relative power'.format(list(bands.keys())[0]),\n",
    "               'R_2', 'Error']]\n",
    "df_ch = df_ch.reset_index(drop=True)\n",
    "\n",
    "# Export results for post-event data\n",
    "df_ch.to_excel('{}/{}/FOOOF/{}_{}_specparam.xlsx'.format(results_folder, exp_folder, exp_condition, ch))\n",
    "display(df_ch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERP DETECTION & IDENTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tminmax = [-200, 1000]\n",
    "\n",
    "# Time windows for different ERP components\n",
    "erp_wins = {'N1' : [40, 170, -1],\n",
    "            'N2' : [180, 350, -1],\n",
    "            'P2' : [100, 260, 1],\n",
    "            'P3' : [270, 500, 1]}\n",
    "\n",
    "# Channel of interest\n",
    "channel_picks = 'Pz'\n",
    "\n",
    "# Event names (i.e. different stimuli) within the epochs\n",
    "event_list = ['GO trial', 'NO-GO trial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directories of clean EEG files and set export directory\n",
    "dir_inprogress = os.path.join(clean_folder, exp_folder)\n",
    "file_dirs, subject_names = arrange.read_files(dir_inprogress, '_clean-epo.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the subjects' directories (EEG files directories)\n",
    "df_erps = pd.DataFrame()\n",
    "arrange.create_results_folders(exp_folder=exp_folder,results_folder=results_folder, erps=True)\n",
    "for i in range(len(file_dirs)):\n",
    "    erp_wins_temp = erp_wins\n",
    "    # Read the clean data from the disk\n",
    "    epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress, subject_names[i]), verbose=False)\n",
    "    \n",
    "    # Apply baseline correction\n",
    "    epochs = epochs.apply_baseline(baseline=(None, 0))\n",
    "\n",
    "    ### create loop here for going through GO and NO-GO's separately\n",
    "    for ev in event_list:\n",
    "        print('{} for {} ({}/{})'.format(ev, subject_names[i], i, len(file_dirs)))\n",
    "        # Create an averaged evoked object from epochs\n",
    "        evoked_signal = epochs[ev].average(picks=channel_picks)\n",
    "\n",
    "        # remove or add if save_evoked === truuuu\n",
    "        evoked_signal.save('{}/{}/ERP analysis/{}_{}_{}_evoked-ave.fif'.format(results_folder, exp_folder,\n",
    "                                                                            subject_names[i], channel_picks,\n",
    "                                                                            ev), overwrite=True)\n",
    "\n",
    "        # Find all the peaks in the evoked signal\n",
    "        minpeak_times, minpeak_mags, maxpeak_times, maxpeak_mags = erpan.find_all_peaks(evoked_signal, epochs, \n",
    "                                                                                        t_range=tminmax, thresh=None,\n",
    "                                                                                        subject_name=subject_names[i],\n",
    "                                                                                        verbose=False, plot=False)\n",
    "        \n",
    "        # Identify which peaks are which ERPs based on the pre-defined ERP time windows\n",
    "        erp_peaks, not_erp_peaks = erpan.identify_erps(evoked_signal, erp_wins_temp, minpeak_times, minpeak_mags,\n",
    "                                                    maxpeak_times, maxpeak_mags, t_range=tminmax, subject_name=subject_names[i],\n",
    "                                                    verbose=False, plot=True, savefig=False,\n",
    "                                                    results_foldername=results_folder, exp_folder=exp_folder)\n",
    "\n",
    "        # After visual inspection, it's possible to re-define the time windows to look for the peak\n",
    "        while input('Do you need to do any manual time window changes? (leave empty if \"no\")') != '':\n",
    "            print('Changing time window parameters for {}'.format(subject_names[i]))\n",
    "            new_time_win = [None, None, None]\n",
    "\n",
    "            # Ask user for which ERP they want to change or add\n",
    "            erp_tochange = input('What ERP time window you want to change (e.g., N1)?')\n",
    "\n",
    "            # Ask user what should be the minimum timepoint of the time window for that ERP\n",
    "            new_time_win[0] = int(input('Enter MIN time of the window in interest for {} (e.g., 50)'.format(erp_tochange)))\n",
    "\n",
    "            # Ask user what should be the maximum timepoint of the time window for that ERP\n",
    "            new_time_win[1] = int(input('Enter MAX time of the window in interest for {} (e.g., 100)'.format(erp_tochange)))\n",
    "\n",
    "            # Ask user whether this ERP should be a postitive (1) or negative (-1) peak\n",
    "            new_time_win[2] = int(input('Enter whether to look for MIN (-1) or MAX (1) voltage for {}'.format(erp_tochange)))\n",
    "\n",
    "            # Change the temporary ERP time window parameters to the user inputted parameters\n",
    "            erp_wins_temp[erp_tochange] = new_time_win\n",
    "            print('Changing', erp_tochange, 'with new time window:', str(new_time_win))\n",
    "\n",
    "            # Use these new parameters to find either minimum or maximum value in that range\n",
    "            try:\n",
    "                erp_peaks = erpan.find_minmax_erp(evoked_signal, erp_peaks, erp_tochange, new_time_win,\n",
    "                                                t_range=tminmax, subject_name=subject_names[i], verbose=False, plot=True,\n",
    "                                                savefig=False, results_foldername=results_folder, exp_folder=exp_folder)\n",
    "            except:\n",
    "                print('Something went wrong with manual ERP detection, try again.')\n",
    "\n",
    "        # Add this/these new temporary ERP to the main dataframe\n",
    "        df_erps_temp = erpan.erp_dict_to_df(erp_peaks, erp_wins_temp, subject_names[i])\n",
    "        df_erps_temp['Event'] = ev\n",
    "        df_erps_temp['Channel'] = channel_picks\n",
    "        df_erps = pd.concat([df_erps, df_erps_temp])\n",
    "        print('ERPs have been found and added to the dataframe for {}'.format(subject_names[i]))\n",
    "        display(df_erps)\n",
    "\n",
    "# Calculate relative peak-to-peak amplitudes between the ERPs\n",
    "print('Adding relative amplitudes for N1-P2, P2-N2, N2-P3')\n",
    "df_erps['N1-P2 amplitude'] = df_erps['P2 amplitude'] - df_erps['N1 amplitude']\n",
    "df_erps['P2-N2 amplitude'] = df_erps['N2 amplitude'] - df_erps['P2 amplitude']\n",
    "df_erps['N2-P3 amplitude'] = df_erps['P3 amplitude'] - df_erps['N2 amplitude']\n",
    "\n",
    "# Export all the detected ERPs to an Excel spreadsheet\n",
    "display(df_erps)\n",
    "df_erps.to_excel('{}/{}/ERP analysis/{}_{}_grandaverage_erps.xlsx'.format(results_folder,exp_folder,exp_condition,channel_picks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA VISUALISATION: ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the figure to results folder or not\n",
    "savefig = True\n",
    "\n",
    "# Subjects which to not plot\n",
    "exclude_subjects = [] # ['OKTOS_0019', 'OKTOS_0024', 'OKTOS_0033']\n",
    "\n",
    "# Channel of interest\n",
    "ch = 'Pz'\n",
    "\n",
    "# Event names (i.e. different stimuli) within the epochs\n",
    "event_list = ['GO trial', 'NO-GO trial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='notebook', font_scale=1.3,\n",
    "              style='whitegrid', palette='muted',\n",
    "              font='sans-serif')\n",
    "\n",
    "# Get directories of clean EEG files and exclude the pre-defined subjects\n",
    "dir_inprogress = os.path.join(clean_folder, exp_folder)\n",
    "file_dirs, subject_names = arrange.read_files(dir_inprogress, \"_clean-epo.fif\",\n",
    "                                      exclude_subjects=exclude_subjects)\n",
    "\n",
    "# Loop through all the subjects' directories (EEG files directories)\n",
    "evoked_signal_go = [None]*len(file_dirs)\n",
    "evoked_signal_nogo = [None]*len(file_dirs)\n",
    "for i in range(len(file_dirs)):\n",
    "    # Read the clean data from the disk\n",
    "    epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress,\n",
    "                                                                subject_names[i]),\n",
    "                                                                verbose=False)\n",
    "    \n",
    "    # Create an averaged evoked object from epochs for both events\n",
    "    evoked_signal_go[i] = epochs['GO trial'].average(picks=ch)\n",
    "    evoked_signal_nogo[i] = epochs['NO-GO trial'].average(picks=ch)\n",
    "\n",
    "# Average all the averaged evoked objects, thereby creating a grand average signals\n",
    "go_master_grand_evoked_data = mne.grand_average(evoked_signal_go).data[0]*1e6\n",
    "go_master_grand_evoked_times = mne.grand_average(evoked_signal_go).times*1e3\n",
    "nogo_master_grand_evoked_data = mne.grand_average(evoked_signal_nogo).data[0]*1e6\n",
    "nogo_master_grand_evoked_times = mne.grand_average(evoked_signal_nogo).times*1e3\n",
    "\n",
    "# Plot all experiments' grand average signals on a single plot\n",
    "fig, ax = plt.subplots(figsize=(6, 4), layout='tight', dpi=150)\n",
    "ax.plot(go_master_grand_evoked_times, go_master_grand_evoked_data, linewidth=3)\n",
    "ax.plot(nogo_master_grand_evoked_times, nogo_master_grand_evoked_data, linewidth=3)\n",
    "ax.legend(event_list)\n",
    "ax.set_title('Grand average of all participants at {}'.format(ch))\n",
    "ax.set_xlim([-200, 1000])\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Amplitude (ÂµV)')\n",
    "ax.grid(which='major', axis='y', alpha=0.2)\n",
    "ax.grid(which='major', axis='x', alpha=0.7)\n",
    "if savefig == True:\n",
    "    plt.savefig(fname='{}/{}/GRAND_erpfig_{}.png'.format(results_folder, exp_folder, ch),\n",
    "                dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
